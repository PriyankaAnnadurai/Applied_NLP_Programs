{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COMgNUmCghvo",
        "outputId": "b281a731-98d3-4b04-f94f-02bd440fe681"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n"
          ]
        }
      ],
      "source": [
        "# Install NLTK if needed\n",
        "!pip install nltk\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('words')\n",
        "from nltk.corpus import words\n",
        "import re\n",
        "from collections import Counter\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5I-D1iagmV2",
        "outputId": "aba93720-b3ad-4d89-c0fe-6696901d4dfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the NLTK words corpus as our vocabulary\n",
        "word_list = words.words()\n",
        "word_freq = Counter(word_list)  # Count frequencies, though here it's a simple corpus with each word appearing once\n",
        "\n",
        "# Define a set of all known words\n",
        "WORD_SET = set(word_list)\n"
      ],
      "metadata": {
        "id": "fr6nGt54gqKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to calculate minimum edit distance\n",
        "def edit_distance(word1, word2):\n",
        "    dp = [[0] * (len(word2) + 1) for _ in range(len(word1) + 1)]\n",
        "    for i in range(len(word1) + 1):\n",
        "        for j in range(len(word2) + 1):\n",
        "            if i == 0:\n",
        "                dp[i][j] = j  # Cost of insertions\n",
        "            elif j == 0:\n",
        "                dp[i][j] = i  # Cost of deletions\n",
        "            elif word1[i - 1] == word2[j - 1]:\n",
        "                dp[i][j] = dp[i - 1][j - 1]  # No change cost\n",
        "            else:\n",
        "                dp[i][j] = 1 + min(dp[i - 1][j],      # Deletion\n",
        "                                   dp[i][j - 1],      # Insertion\n",
        "                                   dp[i - 1][j - 1])  # Substitution\n",
        "    return dp[-1][-1]\n",
        "\n",
        "# Define a function to calculate word probability\n",
        "def word_probability(word, N=sum(word_freq.values())):\n",
        "    return word_freq[word] / N if word in word_freq else 0\n"
      ],
      "metadata": {
        "id": "nCS8Ru5tgrO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Suggest corrections based on edit distance and probability\n",
        "def autocorrect(word):\n",
        "    # If the word is correct, return it as is\n",
        "    if word in WORD_SET:\n",
        "        return word\n",
        "\n",
        "    # Find candidate words within an edit distance of 1 or 2\n",
        "    candidates = [w for w in WORD_SET if edit_distance(word, w) <= 2]\n",
        "\n",
        "    # Choose the candidate with the highest probability\n",
        "    corrected_word = max(candidates, key=word_probability, default=word)\n",
        "\n",
        "    return corrected_word\n"
      ],
      "metadata": {
        "id": "rlbCt5_dgvhr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the function with common misspellings\n",
        "test_words = [\"speling\", \"korrect\", \"exampl\", \"wrld\"]\n",
        "\n",
        "for word in test_words:\n",
        "    print(f\"Original: {word} -> Suggested: {autocorrect(word)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHHR_wqEgytz",
        "outputId": "49beff86-3e6f-49bc-956a-af9d5c34cbe1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original: speling -> Suggested: feeling\n",
            "Original: korrect -> Suggested: horrent\n",
            "Original: exampl -> Suggested: example\n",
            "Original: wrld -> Suggested: word\n"
          ]
        }
      ]
    }
  ]
}